import pandas as pd
import streamlit as st
import re

def extract_info(df, mapping, fields=("è§„æ ¼", "æ™¶åœ†å“å")):
    if df is None or df.empty:
        return pd.DataFrame(columns=["å“å"] + list(fields))
    cols = {"å“å": mapping.get("å“å")}
    for f in fields:
        if f in mapping:
            cols[f] = mapping[f]
    try:
        sub = df[[cols["å“å"]] + list(cols.values())[1:]].copy()
        sub.columns = ["å“å"] + [f for f in fields if f in cols]
        return sub.drop_duplicates(subset=["å“å"])
    except Exception:
        return pd.DataFrame(columns=["å“å"] + list(fields))


def fill_spec_and_wafer_info(main_plan_df: pd.DataFrame,
                              dataframes: dict,
                              additional_sheets: dict,
                              source_nj: pd.DataFrame,
                              field_mappings: dict) -> pd.DataFrame:
    """
    ä¸ºä¸»è®¡åˆ’ DataFrame è¡¥å…¨ è§„æ ¼ å’Œ æ™¶åœ†å“å å­—æ®µï¼ŒæŒ‰ä¼˜å…ˆçº§ä»å¤šä¸ªæ•°æ®æºä¸­é€æ­¥å¡«å……ã€‚
    å¹¶ä¸”å¦‚æœä¸»è®¡åˆ’ä¸­çš„â€œå“åâ€æ­£å¥½åŒ¹é…â€œèµ›å“-æ–°æ—§æ–™å·â€è¡¨é‡Œçš„â€œåŠæˆå“â€ï¼Œ
    å°±ç”¨å¯¹åº”è¡Œçš„â€œæ–°è§„æ ¼â€å’Œâ€œæ–°æ™¶åœ†å“åâ€æ¥è¦†ç›–ä¸»è®¡åˆ’ä¸­çš„å€¼ã€‚

    å‚æ•°ï¼š
        main_plan_df: ä¸»è®¡åˆ’è¡¨ï¼Œå« 'å“å' åˆ—
        dataframes: ä¸»æ–‡ä»¶å­—å…¸ï¼Œæ¥è‡ª classify_files åçš„ self.dataframes
        additional_sheets: è¾…åŠ©è¡¨å­—å…¸ï¼Œå¦‚é¢„æµ‹ã€æ–°æ—§æ–™å·ç­‰
        field_mappings: å„è¡¨å­—æ®µæ˜ å°„é…ç½®ï¼ˆFIELD_MAPPINGSï¼‰

    è¿”å›ï¼š
        å·²è¡¥å…¨è§„æ ¼å’Œæ™¶åœ†å“åçš„ä¸»è®¡åˆ’è¡¨
    """
    sources = [
        ("èµ›å“-æœªäº¤è®¢å•", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-å®‰å…¨åº“å­˜", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æ–°æ—§æ–™å·", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æˆå“åœ¨åˆ¶", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æˆå“åº“å­˜", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-é¢„æµ‹", ("è§„æ ¼",))  # â—é¢„æµ‹ä¸­æ— æ™¶åœ†å“å
    ]

    for sheet, fields in sources:
        source_df = (
            dataframes.get(sheet)
            if sheet in dataframes
            else additional_sheets.get(sheet)
        )
        if source_df is None or source_df.empty:
            continue

        if sheet not in field_mappings:
            continue

        mapping = field_mappings[sheet]
        if "å“å" not in mapping or not all(f in mapping for f in fields):
            continue

        # æ„å»ºæ˜ å°„åˆ—
        try:
            extracted = source_df.copy()
            extracted = extracted[[mapping["å“å"]] + [mapping[f] for f in fields]]
            extracted.columns = ["å“å"] + list(fields)
            extracted["å“å"] = extracted["å“å"].astype(str).str.strip()
            extracted = extracted.drop_duplicates(subset=["å“å"])
        except Exception:
            continue

        # åˆå¹¶å¹¶ä¼˜å…ˆå¡«å…¥ä¸»åˆ—
        main_plan_df = main_plan_df.merge(
            extracted,
            on="å“å",
            how="left",
            suffixes=("", f"_{sheet}")
        )
        for f in fields:
            alt_col = f"{f}_{sheet}"
            if alt_col in main_plan_df.columns:
                main_plan_df[f] = main_plan_df[f].combine_first(main_plan_df[alt_col])
                main_plan_df.drop(columns=[alt_col], inplace=True)

    # é¢å¤–å¤„ç†ï¼šâ€œèµ›å“-æ–°æ—§æ–™å·â€è¡¨é‡Œï¼Œå¦‚æœä¸»è®¡åˆ’ä¸­çš„â€œå“åâ€åŒ¹é…åˆ°â€œåŠæˆå“â€ï¼Œ
    # å°±ç”¨å¯¹åº”è¡Œçš„â€œæ–°è§„æ ¼â€å’Œâ€œæ–°æ™¶åœ†å“åâ€æ¥è¦†ç›–
    if source_nj is not None and not source_nj.empty:
        # å–å‡ºâ€œåŠæˆå“â€â€œæ–°è§„æ ¼â€â€œæ–°æ™¶åœ†å“åâ€â€œæ—§è§„æ ¼â€â€œæ—§æ™¶åœ†å“åâ€äº”åˆ—
        tmp = source_nj[[
            "åŠæˆå“","æ–°è§„æ ¼","æ–°æ™¶åœ†å“å","æ—§è§„æ ¼","æ—§æ™¶åœ†å“å"
        ]].copy()
    
        # é‡å‘½åä¸ºç»Ÿä¸€åˆ—å
        tmp.columns = ["åŠæˆå“", "æ–°è§„æ ¼", "æ–°æ™¶åœ†å“å", "æ—§è§„æ ¼", "æ—§æ™¶åœ†å“å"]
        tmp["åŠæˆå“"] = tmp["åŠæˆå“"].astype(str).str.strip()
    
        # å¦‚æœåŒä¸€ä¸ªâ€œåŠæˆå“â€å¤šè¡Œï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
        tmp = tmp.drop_duplicates(subset=["åŠæˆå“"])
    
        # æ„é€ æ˜ å°„ï¼šå¦‚æœâ€œæ–°è§„æ ¼â€éç©ºåˆ™ç”¨â€œæ–°è§„æ ¼â€ï¼Œå¦åˆ™ç”¨â€œæ—§è§„æ ¼â€
        spec_map = {}
        wafer_map = {}
        for _, row in tmp.iterrows():
            key = row["åŠæˆå“"]
            # æ£€æŸ¥â€œæ–°è§„æ ¼â€æ˜¯å¦ä¸ºç©ºæˆ– NaN
            new_spec = row["æ–°è§„æ ¼"]
            old_spec = row["æ—§è§„æ ¼"]
            spec_map[key] = new_spec if pd.notna(new_spec) and str(new_spec).strip() != "" else old_spec
    
            # æ£€æŸ¥â€œæ–°æ™¶åœ†å“åâ€æ˜¯å¦ä¸ºç©ºæˆ– NaN
            new_wafer = row["æ–°æ™¶åœ†å“å"]
            old_wafer = row["æ—§æ™¶åœ†å“å"]
            wafer_map[key] = new_wafer if pd.notna(new_wafer) and str(new_wafer).strip() != "" else old_wafer
    
        # æ‰¾å‡º main_plan_df ä¸­ï¼Œâ€œå“åâ€æ­£å¥½ç­‰äºæŸä¸ªâ€œåŠæˆå“â€çš„è¡Œ
        mask = main_plan_df["å“å"].astype(str).str.strip().isin(tmp["åŠæˆå“"])
        if mask.any():
            # ç”¨æ˜ å°„å€¼è¦†ç›–â€œè§„æ ¼â€å’Œâ€œæ™¶åœ†å“åâ€
            main_plan_df.loc[mask, "è§„æ ¼"] = main_plan_df.loc[mask, "å“å"].map(spec_map)
            main_plan_df.loc[mask, "æ™¶åœ†å“å"] = main_plan_df.loc[mask, "å“å"].map(wafer_map)

    return main_plan_df



def fill_packaging_info(main_plan_df, dataframes: dict, additional_sheets: dict) -> pd.DataFrame:
    """
    æ ¹æ®å¤šä¸ªæ•°æ®æºå¡«å…¥å°è£…å‚ã€å°è£…å½¢å¼ã€PCã€‚

    å‚æ•°ï¼š
        main_plan_df: ä¸»è®¡åˆ’ DataFrameï¼Œå«â€œå“åâ€åˆ—
        dataframes: æ‰€æœ‰ä¸»æ–‡ä»¶è¡¨æ ¼ï¼ˆå¦‚â€œèµ›å“-æˆå“åœ¨åˆ¶â€ç­‰ï¼‰
        additional_sheets: æ‰€æœ‰è¾…åŠ©æ–‡ä»¶è¡¨æ ¼ï¼ˆå¦‚â€œèµ›å“-æ–°æ—§æ–™å·â€ã€â€œèµ›å“-ä¾›åº”å•†-PCâ€ç­‰ï¼‰

    è¿”å›ï¼š
        å¡«å…¥å­—æ®µåçš„ä¸»è®¡åˆ’ DataFrame
    """

    # âœ… å°è£…å‚åˆ«åæ˜ å°„
    VENDOR_ALIAS = {
        "ç»å…´åƒæ¬£ç”µå­æŠ€æœ¯æœ‰é™å…¬å¸": "ç»å…´åƒæ¬£",
        "å—é€šå®èŠ¯": "å—é€šå®èŠ¯å¾®ç”µå­"
    }

    def normalize_vendor_name(name: str) -> str:
        name = str(name).strip()
        name = name.split("-")[0]  # å»é™¤å¦‚ -CP ç­‰åç¼€
        return VENDOR_ALIAS.get(name, name)

    name_col = "å“å"
    vendor_col = "å°è£…å‚"
    pkg_col = "å°è£…å½¢å¼"

    # ========== 1ï¸âƒ£ å°è£…å‚ã€å°è£…å½¢å¼ æ¥æºé¡ºåº ==========
    sources = [
        ("èµ›å“-æˆå“åœ¨åˆ¶", {"å“å": "äº§å“å“å", "å°è£…å‚": "å·¥ä½œä¸­å¿ƒ", "å°è£…å½¢å¼": "å°è£…å½¢å¼"})
    ]

    for sheet, field_map in sources:
        df = dataframes.get(sheet) if sheet in dataframes else additional_sheets.get(sheet)
        if df is None or df.empty:
            continue

        df = df.copy()
        df[field_map["å“å"]] = df[field_map["å“å"]].astype(str).str.strip()
        df[field_map["å°è£…å‚"]] = df[field_map["å°è£…å‚"]].astype(str).apply(normalize_vendor_name)

        if "å°è£…å½¢å¼" in field_map:
            df[field_map["å°è£…å½¢å¼"]] = df[field_map["å°è£…å½¢å¼"]].astype(str).str.strip()

        # ğŸ‘‰ æ‰“å°åŒ¹é…è®°å½•
        for _, row in main_plan_df.iterrows():
            pname = str(row[name_col]).strip()
            matched_rows = df[df[field_map["å“å"]] == pname]
            if not matched_rows.empty:
                st.write(f"ğŸ” å“å: {pname} åœ¨ `{sheet}` ä¸­åŒ¹é…åˆ°ä»¥ä¸‹è®°å½•ï¼š")
                display_cols = [field_map["å“å"], field_map["å°è£…å‚"]]
                if "å°è£…å½¢å¼" in field_map:
                    display_cols.append(field_map["å°è£…å½¢å¼"])
                st.write(matched_rows[display_cols])

        # æ„é€ æå–åˆ—å¹¶å»é‡
        extract_cols = {
            name_col: df[field_map["å“å"]],
            vendor_col: df[field_map["å°è£…å‚"]]
        }
        if "å°è£…å½¢å¼" in field_map:
            extract_cols[pkg_col] = df[field_map["å°è£…å½¢å¼"]]

        extracted = pd.DataFrame(extract_cols).drop_duplicates()

        # åˆå¹¶
        merged = main_plan_df.merge(extracted, on=name_col, how="left", suffixes=("", f"_{sheet}"))
        st.write(merged)
    
        # ç›´æ¥ç”¨æ–°å€¼è¦†ç›–ä¸»è¡¨åˆ—
        for col in [vendor_col, pkg_col]:
            alt_col = f"{col}_{sheet}"
            if alt_col in merged.columns:
                main_plan_df[col] = merged[alt_col]
        st.write(main_plan_df)
    # ========== 2ï¸âƒ£ é€šè¿‡å°è£…å‚å¡«å…¥ PC ==========
    pc_df = additional_sheets.get("èµ›å“-ä¾›åº”å•†-PC")

    if pc_df is not None and not pc_df.empty:
        pc_df = pc_df.copy()
        pc_df["å°è£…å‚"] = pc_df["å°è£…å‚"].astype(str).apply(normalize_vendor_name)
        pc_df["PC"] = pc_df["PC"].astype(str).str.strip()

        # åˆ é™¤ä¸»è¡¨ä¸­å·²å­˜åœ¨çš„ PC åˆ—
        if "PC" in main_plan_df.columns:
            main_plan_df.drop(columns=["PC"], inplace=True)

        # åˆå¹¶
        merged_pc = main_plan_df.merge(
            pc_df[["å°è£…å‚", "PC"]].drop_duplicates(),
            on="å°è£…å‚",
            how="left"
        )

        # å¡«å› PC åˆ—
        main_plan_df["PC"] = merged_pc["PC"]

    st.write(main_plan_df)
    return main_plan_df
