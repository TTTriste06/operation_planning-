import pandas as pd
import streamlit as st
import re

def extract_info(df, mapping, fields=("è§„æ ¼", "æ™¶åœ†å“å")):
    if df is None or df.empty:
        return pd.DataFrame(columns=["å“å"] + list(fields))
    cols = {"å“å": mapping.get("å“å")}
    for f in fields:
        if f in mapping:
            cols[f] = mapping[f]
    try:
        sub = df[[cols["å“å"]] + list(cols.values())[1:]].copy()
        sub.columns = ["å“å"] + [f for f in fields if f in cols]
        return sub.drop_duplicates(subset=["å“å"])
    except Exception:
        return pd.DataFrame(columns=["å“å"] + list(fields))


def fill_spec_and_wafer_info(main_plan_df: pd.DataFrame,
                              dataframes: dict,
                              additional_sheets: dict,
                              source_nj: pd.DataFrame,
                              field_mappings: dict) -> pd.DataFrame:
    """
    ä¸ºä¸»è®¡åˆ’ DataFrame è¡¥å…¨ è§„æ ¼ å’Œ æ™¶åœ†å“å å­—æ®µï¼ŒæŒ‰ä¼˜å…ˆçº§ä»å¤šä¸ªæ•°æ®æºä¸­é€æ­¥å¡«å……ã€‚
    å¹¶ä¸”å¦‚æœä¸»è®¡åˆ’ä¸­çš„â€œå“åâ€æ­£å¥½åŒ¹é…â€œèµ›å“-æ–°æ—§æ–™å·â€è¡¨é‡Œçš„â€œåŠæˆå“â€ï¼Œ
    å°±ç”¨å¯¹åº”è¡Œçš„â€œæ–°è§„æ ¼â€å’Œâ€œæ–°æ™¶åœ†å“åâ€æ¥è¦†ç›–ä¸»è®¡åˆ’ä¸­çš„å€¼ã€‚

    å‚æ•°ï¼š
        main_plan_df: ä¸»è®¡åˆ’è¡¨ï¼Œå« 'å“å' åˆ—
        dataframes: ä¸»æ–‡ä»¶å­—å…¸ï¼Œæ¥è‡ª classify_files åçš„ self.dataframes
        additional_sheets: è¾…åŠ©è¡¨å­—å…¸ï¼Œå¦‚é¢„æµ‹ã€æ–°æ—§æ–™å·ç­‰
        field_mappings: å„è¡¨å­—æ®µæ˜ å°„é…ç½®ï¼ˆFIELD_MAPPINGSï¼‰

    è¿”å›ï¼š
        å·²è¡¥å…¨è§„æ ¼å’Œæ™¶åœ†å“åçš„ä¸»è®¡åˆ’è¡¨
    """
    sources = [
        ("èµ›å“-æœªäº¤è®¢å•", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-å®‰å…¨åº“å­˜", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æ–°æ—§æ–™å·", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æˆå“åœ¨åˆ¶", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-æˆå“åº“å­˜", ("è§„æ ¼", "æ™¶åœ†å“å")),
        ("èµ›å“-é¢„æµ‹", ("è§„æ ¼",))  # â—é¢„æµ‹ä¸­æ— æ™¶åœ†å“å
    ]

    for sheet, fields in sources:
        source_df = (
            dataframes.get(sheet)
            if sheet in dataframes
            else additional_sheets.get(sheet)
        )
        if source_df is None or source_df.empty:
            continue

        if sheet not in field_mappings:
            continue

        mapping = field_mappings[sheet]
        if "å“å" not in mapping or not all(f in mapping for f in fields):
            continue

        # æ„å»ºæ˜ å°„åˆ—
        try:
            extracted = source_df.copy()
            extracted = extracted[[mapping["å“å"]] + [mapping[f] for f in fields]]
            extracted.columns = ["å“å"] + list(fields)
            extracted["å“å"] = extracted["å“å"].astype(str).str.strip()
            extracted = extracted.drop_duplicates(subset=["å“å"])
        except Exception:
            continue

        # åˆå¹¶å¹¶ä¼˜å…ˆå¡«å…¥ä¸»åˆ—
        main_plan_df = main_plan_df.merge(
            extracted,
            on="å“å",
            how="left",
            suffixes=("", f"_{sheet}")
        )
        for f in fields:
            alt_col = f"{f}_{sheet}"
            if alt_col in main_plan_df.columns:
                main_plan_df[f] = main_plan_df[f].combine_first(main_plan_df[alt_col])
                main_plan_df.drop(columns=[alt_col], inplace=True)

    # é¢å¤–å¤„ç†ï¼šâ€œèµ›å“-æ–°æ—§æ–™å·â€è¡¨é‡Œï¼Œå¦‚æœä¸»è®¡åˆ’ä¸­çš„â€œå“åâ€åŒ¹é…åˆ°â€œåŠæˆå“â€ï¼Œ
    # å°±ç”¨å¯¹åº”è¡Œçš„â€œæ–°è§„æ ¼â€å’Œâ€œæ–°æ™¶åœ†å“åâ€æ¥è¦†ç›–
    if source_nj is not None and not source_nj.empty:
        # å–å‡ºâ€œåŠæˆå“â€â€œæ–°è§„æ ¼â€â€œæ–°æ™¶åœ†å“åâ€â€œæ—§è§„æ ¼â€â€œæ—§æ™¶åœ†å“åâ€äº”åˆ—
        tmp = source_nj[[
            "åŠæˆå“","æ–°è§„æ ¼","æ–°æ™¶åœ†å“å","æ—§è§„æ ¼","æ—§æ™¶åœ†å“å"
        ]].copy()
    
        # é‡å‘½åä¸ºç»Ÿä¸€åˆ—å
        tmp.columns = ["åŠæˆå“", "æ–°è§„æ ¼", "æ–°æ™¶åœ†å“å", "æ—§è§„æ ¼", "æ—§æ™¶åœ†å“å"]
        tmp["åŠæˆå“"] = tmp["åŠæˆå“"].astype(str).str.strip()
    
        # å¦‚æœåŒä¸€ä¸ªâ€œåŠæˆå“â€å¤šè¡Œï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
        tmp = tmp.drop_duplicates(subset=["åŠæˆå“"])
    
        # æ„é€ æ˜ å°„ï¼šå¦‚æœâ€œæ–°è§„æ ¼â€éç©ºåˆ™ç”¨â€œæ–°è§„æ ¼â€ï¼Œå¦åˆ™ç”¨â€œæ—§è§„æ ¼â€
        spec_map = {}
        wafer_map = {}
        for _, row in tmp.iterrows():
            key = row["åŠæˆå“"]
            # æ£€æŸ¥â€œæ–°è§„æ ¼â€æ˜¯å¦ä¸ºç©ºæˆ– NaN
            new_spec = row["æ–°è§„æ ¼"]
            old_spec = row["æ—§è§„æ ¼"]
            spec_map[key] = new_spec if pd.notna(new_spec) and str(new_spec).strip() != "" else old_spec
    
            # æ£€æŸ¥â€œæ–°æ™¶åœ†å“åâ€æ˜¯å¦ä¸ºç©ºæˆ– NaN
            new_wafer = row["æ–°æ™¶åœ†å“å"]
            old_wafer = row["æ—§æ™¶åœ†å“å"]
            wafer_map[key] = new_wafer if pd.notna(new_wafer) and str(new_wafer).strip() != "" else old_wafer
    
        # æ‰¾å‡º main_plan_df ä¸­ï¼Œâ€œå“åâ€æ­£å¥½ç­‰äºæŸä¸ªâ€œåŠæˆå“â€çš„è¡Œ
        mask = main_plan_df["å“å"].astype(str).str.strip().isin(tmp["åŠæˆå“"])
        if mask.any():
            # ç”¨æ˜ å°„å€¼è¦†ç›–â€œè§„æ ¼â€å’Œâ€œæ™¶åœ†å“åâ€
            main_plan_df.loc[mask, "è§„æ ¼"] = main_plan_df.loc[mask, "å“å"].map(spec_map)
            main_plan_df.loc[mask, "æ™¶åœ†å“å"] = main_plan_df.loc[mask, "å“å"].map(wafer_map)

    return main_plan_df



def fill_packaging_info(main_plan_df, dataframes: dict, additional_sheets: dict) -> pd.DataFrame:
    """
    æ ¹æ®å¤šä¸ªæ•°æ®æºå¡«å…¥å°è£…å‚ã€å°è£…å½¢å¼ã€PCã€‚

    ä¼˜å…ˆä»â€œèµ›å“-æ–°æ—§æ–™å·â€è·å– PCï¼›è‹¥æ— ï¼Œå†é€šè¿‡â€œå°è£…å‚â€åŒ¹é…â€œèµ›å“-ä¾›åº”å•†-PCâ€ã€‚
    """

    VENDOR_ALIAS = {
        "ç»å…´åƒæ¬£ç”µå­æŠ€æœ¯æœ‰é™å…¬å¸": "ç»å…´åƒæ¬£",
        "å—é€šå®èŠ¯": "å—é€šå®èŠ¯å¾®ç”µå­"
    }

    def normalize_vendor_name(name: str) -> str:
        name = str(name).strip()
        name = name.split("-")[0]
        return VENDOR_ALIAS.get(name, name)

    name_col = "å“å"
    vendor_col = "å°è£…å‚"
    pkg_col = "å°è£…å½¢å¼"

    # ========== 1ï¸âƒ£ å°è£…å‚ã€å°è£…å½¢å¼ã€PCï¼ˆç¬¬ä¸€ä¼˜å…ˆï¼‰ ==========
    df_map = additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·")
    if df_map is not None and not df_map.empty:
        df_map = df_map.copy()
        df_map["æ–°å“å"] = df_map["æ–°å“å"].astype(str).str.strip()
        df_map["å°è£…å‚"] = df_map["å°è£…å‚"].astype(str).apply(normalize_vendor_name)
        df_map["å°è£…å½¢å¼"] = df_map["å°è£…å½¢å¼"].astype(str).str.strip()
        df_map["PC"] = df_map["PC"].astype(str).str.strip()

        for idx, row in main_plan_df.iterrows():
            pname = str(row[name_col]).strip()
            matched = df_map[df_map["æ–°å“å"] == pname]
            if matched.empty:
                continue

            if pd.isna(row[vendor_col]) and matched.iloc[0]["å°è£…å‚"]:
                main_plan_df.at[idx, vendor_col] = matched.iloc[0]["å°è£…å‚"]

            if pd.isna(row.get(pkg_col)) and matched.iloc[0]["å°è£…å½¢å¼"]:
                main_plan_df.at[idx, pkg_col] = matched.iloc[0]["å°è£…å½¢å¼"]

            # âœ… ä¼˜å…ˆå¡«å…¥ PC
            if "PC" not in main_plan_df.columns:
                main_plan_df["PC"] = ""
            if pd.isna(row.get("PC")) or row["PC"] == "":
                pc_value = matched.iloc[0]["PC"]
                if pc_value:
                    main_plan_df.at[idx, "PC"] = pc_value

    # ========== 2ï¸âƒ£ å°è£…å‚ã€å°è£…å½¢å¼è¡¥å……ï¼ˆå…¶ä»–æ¥æºï¼‰ ==========
    sources = [
        ("èµ›å“-æˆå“åœ¨åˆ¶", {"å“å": "äº§å“å“å", "å°è£…å‚": "å·¥ä½œä¸­å¿ƒ", "å°è£…å½¢å¼": "å°è£…å½¢å¼"}),
        ("èµ›å“-ä¸‹å•æ˜ç»†", {"å“å": "å›è´§æ˜ç»†_å›è´§å“å", "å°è£…å‚": "ä¾›åº”å•†åç§°"})
    ]

    for sheet, field_map in sources:
        df = dataframes.get(sheet) if sheet in dataframes else additional_sheets.get(sheet)
        if df is None or df.empty:
            continue

        df = df.copy()
        if field_map["å“å"] not in df.columns or field_map["å°è£…å‚"] not in df.columns:
            continue

        df[field_map["å“å"]] = df[field_map["å“å"]].astype(str).str.strip()
        df[field_map["å°è£…å‚"]] = df[field_map["å°è£…å‚"]].astype(str).apply(normalize_vendor_name)
        if "å°è£…å½¢å¼" in field_map and field_map["å°è£…å½¢å¼"] in df.columns:
            df[field_map["å°è£…å½¢å¼"]] = df[field_map["å°è£…å½¢å¼"]].astype(str).str.strip()

        for idx, row in main_plan_df.iterrows():
            pname = str(row[name_col]).strip()
            matched = df[df[field_map["å“å"]] == pname]
            if matched.empty:
                continue

            if pd.isna(row[vendor_col]):
                main_plan_df.at[idx, vendor_col] = matched.iloc[0][field_map["å°è£…å‚"]]

            if "å°è£…å½¢å¼" in field_map and pd.isna(row.get(pkg_col)):
                main_plan_df.at[idx, pkg_col] = matched.iloc[0][field_map["å°è£…å½¢å¼"]]

    # ========== 3ï¸âƒ£ PC è¡¥å……ï¼šé€šè¿‡å°è£…å‚åŒ¹é… ==========
    pc_df = additional_sheets.get("èµ›å“-ä¾›åº”å•†-PC")
    
    if pc_df is not None and not pc_df.empty:
        pc_df = pc_df.copy()
        pc_df.columns = pc_df.columns.str.strip()  # é˜²æ­¢åˆ—åä¸­æœ‰ç©ºæ ¼
        if "å°è£…å‚" not in pc_df.columns or "PC" not in pc_df.columns:
            raise ValueError("âŒ â€˜èµ›å“-ä¾›åº”å•†-PCâ€™ ç¼ºå°‘å¿…è¦å­—æ®µï¼šâ€˜å°è£…å‚â€™ æˆ– â€˜PCâ€™")
    
        pc_df["å°è£…å‚"] = pc_df["å°è£…å‚"].astype(str).apply(normalize_vendor_name)
        pc_df["PC"] = pc_df["PC"].astype(str).str.strip()
    
        # ä¸»è¡¨å°è£…å‚ä¹Ÿæ ‡å‡†åŒ–
        main_plan_df["å°è£…å‚"] = main_plan_df["å°è£…å‚"].astype(str).apply(normalize_vendor_name)
    
        if "PC" not in main_plan_df.columns:
            main_plan_df["PC"] = ""
    
        # åªå¡«è¡¥ç©ºå€¼
        mask_empty_pc = main_plan_df["PC"].isna() | (main_plan_df["PC"] == "")
        df_needs_pc = main_plan_df[mask_empty_pc].copy()
    
        # æ‰§è¡Œ merge
        if "PC" in main_plan_df.columns:
            main_plan_df.drop(columns=["PC"], inplace=True)
        
        # åˆå¹¶ååªæœ‰ä¸€ä¸ª PC åˆ—
        main_plan_df = main_plan_df.merge(
            pc_df[["å°è£…å‚", "PC"]].drop_duplicates(),
            on="å°è£…å‚",
            how="left"
        )


        st.write(pc_df)
        st.write(main_plan_df)
        
        # ğŸ”’ æ£€æŸ¥ merge åæ˜¯å¦å« PC åˆ—
        if "PC" not in main_plan_df.columns:
            raise ValueError("âŒ åˆå¹¶åæ²¡æœ‰ç”Ÿæˆ PC åˆ—ï¼Œå¯èƒ½â€˜ä¾›åº”å•†-PCâ€™è¡¨æ ¼å¼é”™è¯¯æˆ–æ— åŒ¹é…")
    
        # âœ… å›å¡« PC
        main_plan_df.loc[mask_empty_pc, "PC"] = main_plan_df["PC"].values
    
        # å¯é€‰è°ƒè¯•
        filled_count = merged["PC"].notna().sum()
        st.write(f"âœ… é€šè¿‡å°è£…å‚è¡¥å…… PCï¼šæˆåŠŸå¡«å…¥ {filled_count} æ¡")
        st.write(main_plan_df)


    return main_plan_df
