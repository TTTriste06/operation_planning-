import pandas as pd
import streamlit as st
from io import BytesIO
from datetime import datetime

from config import FILE_KEYWORDS, OUTPUT_FILENAME_PREFIX, FIELD_MAPPINGS
from mapping_utils import clean_mapping_headers, apply_mapping_and_merge, apply_extended_substitute_mapping


class PivotProcessor:
    def __init__(self):
        self.dataframes = {}
        self.additional_sheets = {}

    def classify_files(self, uploaded_files):
        """
        æ ¹æ®å…³é”®è¯è¯†åˆ«ä¸Šä¼ çš„ä¸»æ•°æ®æ–‡ä»¶ï¼Œå¹¶èµ‹äºˆæ ‡å‡†ä¸­æ–‡åç§°
        """
        for file in uploaded_files:
            filename = file.name
            for keyword, standard_name in FILE_KEYWORDS.items():
                if keyword in filename:
                    self.dataframes[standard_name] = pd.read_excel(file)
                    break

    def process(self):
        """
        åˆ›å»ºâ€œä¸»è®¡åˆ’â€å¹¶å¯¹æ‰€æœ‰æ•°æ®è¡¨ä¸­çš„â€œå“åâ€å­—æ®µè¿›è¡Œæ ‡å‡†åŒ–æ›¿æ¢ï¼ˆæ–°æ—§æ–™å· + æ›¿ä»£æ–™å·ï¼‰ã€‚
        """
        # æ–°å»ºä¸»è®¡åˆ’df
        main_plan_df = pd.DataFrame()

        # æå–æ–°æ—§æ–™å·
        mapping_df = self.additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·")
        if mapping_df is None or mapping_df.empty:
            raise ValueError("âŒ ç¼ºå°‘æ–°æ—§æ–™å·æ˜ å°„è¡¨ï¼Œæ— æ³•è¿›è¡Œå“åæ›¿æ¢ã€‚")

        # æ›¿æ¢å“å è¦å¤„ç†çš„æ‰€æœ‰è¡¨ï¼ˆä¸»è¡¨ + è¾…åŠ©è¡¨ï¼Œé™¤äº† mapping å’Œ supplierï¼‰
        all_tables = {
            **self.dataframes,
            **{k: v for k, v in self.additional_sheets.items() if k not in ["èµ›å“-æ–°æ—§æ–™å·", "èµ›å“-ä¾›åº”å•†-PC"]}
        }
    
        for sheet_name, df in all_tables.items():
            if sheet_name not in FIELD_MAPPINGS:
                st.warning(f"âš ï¸ {sheet_name} æ²¡æœ‰åœ¨ FIELD_MAPPINGS ä¸­æ³¨å†Œï¼Œè·³è¿‡æ›¿æ¢")
                continue
    
            field_map = FIELD_MAPPINGS[sheet_name]
            if "å“å" not in field_map:
                st.warning(f"âš ï¸ {sheet_name} çš„ FIELD_MAPPINGS ä¸­æœªå®šä¹‰ 'å“å' æ˜ å°„ï¼Œè·³è¿‡")
                continue
    
            actual_name_col = field_map["å“å"]
            if actual_name_col not in df.columns:
                st.warning(f"âš ï¸ {sheet_name} ä¸­æ‰¾ä¸åˆ°åˆ—ï¼š{actual_name_col}ï¼Œè·³è¿‡")
                continue
    
            try:
                df, keys_main = apply_mapping_and_merge(df, mapping_df, field_map={"å“å": actual_name_col})
                df, keys_sub = apply_extended_substitute_mapping(df, mapping_df, field_map={"å“å": actual_name_col})
                # æ›´æ–°å¤„ç†åçš„è¡¨
                if sheet_name in self.dataframes:
                    self.dataframes[sheet_name] = df
                else:
                    self.additional_sheets[sheet_name] = df
            except Exception as e:
                st.error(f"âŒ æ›¿æ¢ {sheet_name} ä¸­çš„å“åå¤±è´¥ï¼š{e}")

        # âœ… è¾“å‡ºæ‰€æœ‰å¤„ç†å®Œçš„è¡¨ï¼ˆç”¨äºè°ƒè¯•æŸ¥çœ‹ï¼‰
        st.markdown("## âœ… å·²å¤„ç†è¡¨æ ¼é¢„è§ˆï¼ˆä»…å‰5è¡Œï¼‰")
        
        for name, df in {**self.dataframes, **self.additional_sheets}.items():
            st.subheader(f"ğŸ“„ {name}")
            st.dataframe(df.head(), use_container_width=True)

    
        return {"ä¸»è®¡åˆ’": main_plan_df}

        


    def export_to_excel(self, sheet_dict: dict):
        """
        æ¥æ”¶ä¸€ä¸ªåŒ…å«å¤šä¸ª sheet çš„ dictï¼Œå¹¶å†™å…¥ Excel æ–‡ä»¶ã€‚
        """
        output = BytesIO()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{OUTPUT_FILENAME_PREFIX}_{timestamp}.xlsx"
    
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            for sheet_name, df in sheet_dict.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)
    
        output.seek(0)
        return filename, output


    def set_additional_data(self, sheets_dict):
        """
        è®¾ç½®è¾…åŠ©æ•°æ®è¡¨ï¼Œå¦‚ é¢„æµ‹ã€å®‰å…¨åº“å­˜ã€æ–°æ—§æ–™å· ç­‰
        """
        self.additional_sheets = sheets_dict or {}
    
        # âœ… å¯¹æ–°æ—§æ–™å·è¿›è¡Œåˆ—åæ¸…æ´—
        mapping_df = self.additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·")
        if mapping_df is not None and not mapping_df.empty:
            try:
                cleaned = clean_mapping_headers(mapping_df)
                self.additional_sheets["èµ›å“-æ–°æ—§æ–™å·"] = cleaned
            except Exception as e:
                raise ValueError(f"âŒ æ–°æ—§æ–™å·è¡¨æ¸…æ´—å¤±è´¥ï¼š{e}")
