import re
import pandas as pd
import streamlit as st
from io import BytesIO
from datetime import datetime
from openpyxl.utils import get_column_letter
from openpyxl import load_workbook
from openpyxl.styles import Font, Alignment

from config import FILE_KEYWORDS, OUTPUT_FILENAME_PREFIX, FIELD_MAPPINGS, pivot_config, RENAME_MAP
from excel_utils import adjust_column_width
from mapping_utils import (
    clean_mapping_headers, 
    replace_all_names_with_mapping, 
    apply_mapping_and_merge, 
    apply_extended_substitute_mapping,
    apply_all_name_replacements
)
from data_utils import (
    extract_info, 
    fill_spec_and_wafer_info, 
    fill_packaging_info
)
from summary import (
    merge_safety_inventory,
    merge_safety_header,
    append_unfulfilled_summary_columns_by_date,
    merge_unfulfilled_order_header, 
    append_forecast_to_summary,
    merge_forecast_header,
    merge_finished_inventory_with_warehouse_types,
    merge_inventory_header,
    append_product_in_progress,
    merge_product_in_progress_header
)
from production_plan import (
    init_monthly_fields,
    generate_monthly_fg_plan,
    aggregate_actual_fg_orders,
    aggregate_actual_sfg_orders,
    aggregate_actual_arrivals,
    aggregate_sales_quantity_and_amount,
    generate_monthly_semi_plan,
    generate_monthly_adjust_plan,
    generate_monthly_return_adjustment,
    generate_monthly_return_plan,
    format_monthly_grouped_headers,
    highlight_production_plan_cells,
    drop_last_forecast_month_columns
)
from sheet_add import clean_df, append_all_standardized_sheets
from pivot_generator import generate_monthly_pivots, standardize_uploaded_keys

class PivotProcessor:
    def process(self, uploaded_files: dict, output_buffer, additional_sheets: dict = None):
        """
        æ›¿æ¢å“åã€æ–°å»ºä¸»è®¡åˆ’è¡¨ï¼Œå¹¶ç›´æ¥å†™å…¥ Excel æ–‡ä»¶ï¼ˆå«åˆ—å®½è°ƒæ•´ã€æ ‡é¢˜è¡Œï¼‰ã€‚
        """
        # === æ ‡å‡†åŒ–ä¸Šä¼ æ–‡ä»¶å ===
        self.dataframes = {}
        for filename, file_obj in uploaded_files.items():
            matched = False
            for keyword, standard_name in FILE_KEYWORDS.items():
                if keyword in filename:
                    self.dataframes[standard_name] = pd.read_excel(file_obj)
                    matched = True
                    break
            if not matched:
                st.warning(f"âš ï¸ ä¸Šä¼ æ–‡ä»¶ `{filename}` æœªè¯†åˆ«å…³é”®è¯ï¼Œè·³è¿‡")
        
        self.additional_sheets = additional_sheets
        mapping_df = self.additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·")
        if mapping_df is None or mapping_df.empty:
            raise ValueError("âŒ ç¼ºå°‘æ–°æ—§æ–™å·æ˜ å°„è¡¨ï¼Œæ— æ³•è¿›è¡Œå“åæ›¿æ¢ã€‚")

        # === æ„å»ºä¸»è®¡åˆ’ ===
        headers = ["æ™¶åœ†å“å", "è§„æ ¼", "å“å", "å°è£…å‚", "å°è£…å½¢å¼", "PC"]
        main_plan_df = pd.DataFrame(columns=headers)

        ## == å“å ==
        df_unfulfilled = self.dataframes.get("èµ›å“-æœªäº¤è®¢å•")
        df_forecast = self.additional_sheets.get("èµ›å“-é¢„æµ‹")

        name_unfulfilled = []
        name_forecast = []

        if df_unfulfilled is not None and not df_unfulfilled.empty:
            col_name = FIELD_MAPPINGS["èµ›å“-æœªäº¤è®¢å•"]["å“å"]
            name_unfulfilled = df_unfulfilled[col_name].astype(str).str.strip().tolist()

        if df_forecast is not None and not df_forecast.empty:
            col_name = FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"]["å“å"]
            name_forecast = df_forecast[col_name].astype(str).str.strip().tolist()

        all_names = pd.Series(name_unfulfilled + name_forecast)
        all_names = replace_all_names_with_mapping(all_names, mapping_df)


        main_plan_df = main_plan_df.reindex(index=range(len(all_names)))
        if not all_names.empty:
            main_plan_df["å“å"] = all_names.values

        ## == è§„æ ¼å’Œæ™¶åœ† ==
        main_plan_df = fill_spec_and_wafer_info(
            main_plan_df,
            self.dataframes,
            self.additional_sheets,
            FIELD_MAPPINGS
        )

        ## == å°è£…å‚ï¼Œå°è£…å½¢å¼å’ŒPC ==
        main_plan_df = fill_packaging_info(
            main_plan_df,
            dataframes=self.dataframes,
            additional_sheets=self.additional_sheets
        )

        ## == æ›¿æ¢æ–°æ—§æ–™å·ã€æ›¿ä»£æ–™å· ==
        st.write(self.additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"])
        df_new = self.additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"]
        st.write(df_new)
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-å®‰å…¨åº“å­˜"])
        st.write(self.additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-å®‰å…¨åº“å­˜"])
        additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"] = df_new

        st.write(self.additional_sheets["èµ›å“-å®‰å…¨åº“å­˜"])

        df_new = self.additional_sheets["èµ›å“-é¢„æµ‹"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-é¢„æµ‹"])
        additional_sheets["èµ›å“-é¢„æµ‹"] = df_new

        df_new = self.dataframes["èµ›å“-æœªäº¤è®¢å•"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æœªäº¤è®¢å•"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æœªäº¤è®¢å•"])
        additional_sheets["èµ›å“-æœªäº¤è®¢å•"] = df_new

        df_new = self.dataframes["èµ›å“-æˆå“åº“å­˜"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æˆå“åº“å­˜"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æˆå“åº“å­˜"])
        additional_sheets["èµ›å“-æˆå“åº“å­˜"] = df_new

        df_new = self.dataframes["èµ›å“-æˆå“åœ¨åˆ¶"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æˆå“åœ¨åˆ¶"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æˆå“åœ¨åˆ¶"])
        additional_sheets["èµ›å“-æˆå“åœ¨åˆ¶"] = df_new

        df_new = self.dataframes["èµ›å“-CPåœ¨åˆ¶"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-CPåœ¨åˆ¶"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-CPåœ¨åˆ¶"])
        additional_sheets["èµ›å“-CPåœ¨åˆ¶"] = df_new

        df_new = self.dataframes["èµ›å“-æ™¶åœ†åº“å­˜"]
        df_new, _ = apply_mapping_and_merge(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æ™¶åœ†åº“å­˜"])
        df_new, _ = apply_extended_substitute_mapping(df_new, mapping_df, FIELD_MAPPINGS["èµ›å“-æ™¶åœ†åº“å­˜"])
        additional_sheets["èµ›å“-æ™¶åœ†åº“å­˜"] = df_new



            


        """
        for sheet_name, df in {
            **self.dataframes,
            **{k: v for k, v in additional_sheets.items() if k not in ["èµ›å“-æ–°æ—§æ–™å·", "èµ›å“-ä¾›åº”å•†-PC"]}
        }.items():
            if sheet_name not in FIELD_MAPPINGS:
                st.warning(f"âš ï¸ {sheet_name} æœªåœ¨ FIELD_MAPPINGS æ³¨å†Œï¼Œè·³è¿‡æ›¿æ¢")
                continue
        
            field_map = FIELD_MAPPINGS[sheet_name]
            if "å“å" not in field_map:
                st.warning(f"âš ï¸ {sheet_name} çš„ FIELD_MAPPINGS ä¸­æœªå®šä¹‰ 'å“å'ï¼Œè·³è¿‡")
                continue
        
            actual_name_col = field_map["å“å"]
            if actual_name_col not in df.columns:
                st.warning(f"âš ï¸ {sheet_name} ä¸­æ‰¾ä¸åˆ°åˆ—ï¼š{actual_name_col}ï¼Œè·³è¿‡")
                continue
            try:
                df, _ = apply_mapping_and_merge(df, mapping_df, field_map={"å“å": actual_name_col})
                df, _ = apply_extended_substitute_mapping(df, mapping_df, field_map={"å“å": actual_name_col})
                st.write("3")
                st.write(additional_sheets)
                if sheet_name in self.dataframes:
                    self.dataframes[sheet_name] = df
                    st.write("4")
                    st.write(additional_sheets)
                else:
                    additional_sheets[sheet_name] = df
                    st.write("5")
                    st.write(additional_sheets)
            except Exception as e:
                st.error(f"âŒ æ›¿æ¢ {sheet_name} ä¸­çš„å“åå¤±è´¥ï¼š{e}")
        """
        ## == å®‰å…¨åº“å­˜ ==
        safety_df = self.additional_sheets.get("èµ›å“-å®‰å…¨åº“å­˜")
        if safety_df is not None and not safety_df.empty:
            main_plan_df, unmatched_safety = merge_safety_inventory(main_plan_df, safety_df)
            st.success("âœ… å·²åˆå¹¶å®‰å…¨åº“å­˜æ•°æ®")
        
        ## == æœªäº¤è®¢å• ==
        unfulfilled_df = self.dataframes.get("èµ›å“-æœªäº¤è®¢å•")
        if unfulfilled_df is not None and not unfulfilled_df.empty:
            main_plan_df, unmatched_unfulfilled = append_unfulfilled_summary_columns_by_date(main_plan_df, unfulfilled_df)
            st.success("âœ… å·²åˆå¹¶æœªäº¤è®¢å•æ•°æ®")


        ## == é¢„æµ‹ ==
        forecast_df = self.additional_sheets.get("èµ›å“-é¢„æµ‹")
        if forecast_df is not None and not forecast_df.empty:
            main_plan_df, unmatched_forecast = append_forecast_to_summary(main_plan_df, forecast_df)
            st.success("âœ… å·²åˆå¹¶é¢„æµ‹æ•°æ®")

        ## == æˆå“åº“å­˜ ==
        finished_df = self.dataframes.get("èµ›å“-æˆå“åº“å­˜")
        if finished_df is not None and not finished_df.empty:
            main_plan_df, unmatched_finished = merge_finished_inventory_with_warehouse_types(main_plan_df, finished_df, mapping_df)
            st.success("âœ… å·²åˆå¹¶æˆå“åº“å­˜æ•°æ®")

        ## == æˆå“åœ¨åˆ¶ ==
        product_in_progress_df = self.dataframes.get("èµ›å“-æˆå“åœ¨åˆ¶")
        if product_in_progress_df is not None and not product_in_progress_df.empty:
            main_plan_df, unmatched_in_progress = append_product_in_progress(main_plan_df, product_in_progress_df, mapping_df)
            st.success("âœ… å·²åˆå¹¶æˆå“åœ¨åˆ¶æ•°æ®")

        # === æŠ•å•è®¡åˆ’ ===
        forecast_months = init_monthly_fields(main_plan_df)

        # æˆå“&åŠæˆå“å®é™…æŠ•å•
        df_order = self.dataframes.get("èµ›å“-ä¸‹å•æ˜ç»†", pd.DataFrame())
        main_plan_df = aggregate_actual_fg_orders(main_plan_df, df_order, forecast_months)
        main_plan_df = aggregate_actual_sfg_orders(main_plan_df, df_order, mapping_df, forecast_months)

        # å›è´§å®é™…
        df_arrival = self.dataframes.get("èµ›å“-åˆ°è´§æ˜ç»†", pd.DataFrame())
        main_plan_df = aggregate_actual_arrivals(main_plan_df, df_arrival, forecast_months)

        # é”€å”®æ•°é‡&é”€å”®é‡‘é¢
        df_sales = self.dataframes.get("èµ›å“-é”€è´§æ˜ç»†", pd.DataFrame())
        main_plan_df = aggregate_sales_quantity_and_amount(main_plan_df, df_sales, forecast_months)

        # æˆå“æŠ•å•è®¡åˆ’
        main_plan_df = generate_monthly_fg_plan(main_plan_df, forecast_months)

        # åŠæˆå“æŠ•å•è®¡åˆ’
        main_plan_df = generate_monthly_semi_plan(main_plan_df, forecast_months, mapping_df)

        # æŠ•å•è®¡åˆ’è°ƒæ•´
        main_plan_df = generate_monthly_adjust_plan(main_plan_df)

        # å›è´§è®¡åˆ’
        main_plan_df = generate_monthly_return_plan(main_plan_df)

        
        # å›è´§è®¡åˆ’è°ƒæ•´
        main_plan_df = generate_monthly_return_adjustment(main_plan_df)

        
        # æ£€æŸ¥
        main_plan_df = drop_last_forecast_month_columns(main_plan_df, forecast_months)

        
        # === å†™å…¥ Excel æ–‡ä»¶ï¼ˆä¸»è®¡åˆ’ï¼‰===
        timestamp = datetime.now().strftime("%Y%m%d")
        with pd.ExcelWriter(output_buffer, engine="openpyxl") as writer:
            main_plan_df = clean_df(main_plan_df)
            main_plan_df.to_excel(writer, sheet_name="ä¸»è®¡åˆ’", index=False, startrow=1)
            append_all_standardized_sheets(writer, uploaded_files, self.additional_sheets)
            
            # æ›¿æ¢ä¸Šä¼ æ–‡ä»¶ key ä¸ºæ ‡å‡†å
            standardized_files = standardize_uploaded_keys(uploaded_files, RENAME_MAP)
            
            # å°† UploadedFile è¯»å–ä¸º DataFrame
            parsed_dataframes = {
                filename: pd.read_excel(file)  # æˆ–æå‰ parse å®Œæˆçš„ DataFrame dict
                for filename, file in standardized_files.items()
            }
            
            pivot_tables = generate_monthly_pivots(parsed_dataframes, pivot_config)
            
            for sheet_name, df in pivot_tables.items():
                df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
                
            
            # å†™å®Œåæ‰‹åŠ¨è°ƒæ•´æ‰€æœ‰é€è§†è¡¨ sheet çš„åˆ—å®½
            for sheet_name, df in pivot_tables.items():
                ws = writer.book[sheet_name]
                for col_cells in ws.columns:
                    max_length = 0
                    col_letter = col_cells[0].column_letter
                    for cell in col_cells:
                        try:
                            if cell.value:
                                max_length = max(max_length, len(str(cell.value)))
                        except:
                            pass
                    adjusted_width = max_length * 1.2 + 10
                    ws.column_dimensions[col_letter].width = min(adjusted_width, 50)
            
            ws = writer.book["ä¸»è®¡åˆ’"]
            ws.cell(row=1, column=1, value=f"ä¸»è®¡åˆ’ç”Ÿæˆæ—¶é—´ï¼š{timestamp}")
            

            legend_cell = ws.cell(row=1, column=3)
            legend_cell.value = (
                "ğŸŸ¥ < 0    "
                "ğŸŸ¨ < å®‰å…¨åº“å­˜    "
                "ğŸŸ§ > 2 Ã— å®‰å…¨åº“å­˜"
            )
            legend_cell.alignment = Alignment(wrap_text=True, vertical="center", horizontal="left")

            merge_safety_header(ws, main_plan_df)
            merge_unfulfilled_order_header(ws)
            merge_forecast_header(ws)
            merge_inventory_header(ws)
            merge_product_in_progress_header(ws)

            format_monthly_grouped_headers(ws)
            highlight_production_plan_cells(ws, main_plan_df)


            adjust_column_width(ws)


            # è®¾ç½®å­—ä½“åŠ ç²—ï¼Œè¡Œé«˜ä¹Ÿè°ƒé«˜ä¸€ç‚¹
            bold_font = Font(bold=True)
            ws.row_dimensions[2].height = 35
    
            # éå†è¿™ä¸€è¡Œæ‰€æœ‰å·²ç”¨åˆ°çš„åˆ—ï¼Œå¯¹å•å…ƒæ ¼å­—ä½“åŠ ç²—ã€å±…ä¸­ã€å‚ç›´å±…ä¸­
            max_col = ws.max_column
            for col_idx in range(1, max_col + 1):
                cell = ws.cell(row=2, column=col_idx)
                cell.font = bold_font
                # å‚ç›´æ°´å¹³å±…ä¸­
                cell.alignment = Alignment(horizontal="center", vertical="center")

            # è‡ªåŠ¨ç­›é€‰
            last_col_letter = get_column_letter(ws.max_column)
            ws.auto_filter.ref = f"A2:{last_col_letter}2"
        
            # å†»ç»“
            ws.freeze_panes = "D1"



        output_buffer.seek(0)

        
    def set_additional_data(self, sheets_dict):
        """
        è®¾ç½®è¾…åŠ©æ•°æ®è¡¨ï¼Œå¦‚ é¢„æµ‹ã€å®‰å…¨åº“å­˜ã€æ–°æ—§æ–™å· ç­‰
        """
        self.additional_sheets = sheets_dict or {}
    
        # âœ… å¯¹æ–°æ—§æ–™å·è¿›è¡Œåˆ—åæ¸…æ´—
        mapping_df = self.additional_sheets.get("èµ›å“-æ–°æ—§æ–™å·")
        if mapping_df is not None and not mapping_df.empty:
            try:
                cleaned = clean_mapping_headers(mapping_df)
                self.additional_sheets["èµ›å“-æ–°æ—§æ–™å·"] = cleaned
            except Exception as e:
                raise ValueError(f"âŒ æ–°æ—§æ–™å·è¡¨æ¸…æ´—å¤±è´¥ï¼š{e}")
